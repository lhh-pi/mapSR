train_dataset:
  dataset:
    name: image-folder
    args:
      root_path: 'map/map_train_HR'
      repeat: 20
      cache: in_memory
  wrapper:
    name: sr-implicit-downsampled
    args:
      inp_size: 48
      scale_max: 2
      augment: true
  batch_size: 4

val_dataset:
  dataset:
    name: image-folder
    args:
      root_path: 'map/val'
      first_k: 60
      repeat: 1
      cache: in_memory
  wrapper:
    name: sr-implicit-downsampled
    args:
      inp_size: 48
      scale_max: 2
  batch_size: 32

data_norm:
#  inp: {sub: [0.5], div: [0.5]}
#  gt: {sub: [0.5], div: [0.5]}
#def __init__(self,
#             img_size: int = 64,
#             patch_size: int = 1,
#             in_chans: int = 3,
#             embed_dim: int = 96,
#             depths: List[int] = [6, 6, 6, 6],
#             num_heads: List[int] = [6, 6, 6, 6],
#             window_size: int = 7,
#             mlp_ratio: float = 4.,
#             qkv_bias: bool = True,
#             qk_scale: Any = None,
#             drop_rate: float = 0.,
#             attn_drop_rate: float = 0.,
#             drop_path_rate: float = 0.1,
#             norm_layer: Type[LayerNorm] = nn.LayerNorm,
#             ape: bool = False,
#             patch_norm: bool = True,
#             use_checkpoint: bool = False,
#             upscale: int = 2,
#             img_range: float = 1.,
#             upsampler: str = '',
#             resi_connection: str = '1conv',
#             **kwargs: Any) -> None

model:
  name: mapsr
  args:
    scale: 2
  sd:

optimizer:
  name: adam
  args:
    lr: 1.e-4
epoch_max: 1000
multi_step_lr:
#  milestones: [200, 400, 600, 800]
#  gamma: 0.5

epoch_val: 1
epoch_save: 200
